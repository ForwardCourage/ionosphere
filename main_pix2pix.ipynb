{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50be7d24",
   "metadata": {},
   "source": [
    "# Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a92685cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from model import *\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder, DatasetFolder\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7baf1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdeaefe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualImageFolderDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_input, root_output, transform=None):\n",
    "        self.input_data = ImageFolder(root=root_input, transform=transform)\n",
    "        self.output_data = ImageFolder(root=root_output, transform=transform)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.input_data[idx][0], self.output_data[idx][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47e30073",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_input = 'Images_jet/input'\n",
    "root_output = 'Images_jet/output'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),  # Resize the images\n",
    "    transforms.ToTensor(),           # Convert to PyTorch tensor\n",
    "])\n",
    "\n",
    "\n",
    "dataset = DualImageFolderDataset(root_input, root_output, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c51a460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test subsets using sklearn's train_test_split\n",
    "train_indices, test_indices = train_test_split(range(len(dataset)), test_size=0.1, random_state=40)\n",
    "\n",
    "# Create Subset instances for train and test sets\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Create DataLoader instances for train and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Now you can use train_loader and test_loader for iterating over your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "542a1dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(g_conv_dim = 64 , d_conv_dim = 64 , n_res_blocks = 6):\n",
    "    \n",
    "    '''builds the generator and discriminators'''\n",
    "    \n",
    "    #Generators\n",
    "    G_XtoY = Generator(conv_dim = g_conv_dim , res_blocks = n_res_blocks)\n",
    "    G_YtoX = Generator(conv_dim = g_conv_dim , res_blocks = n_res_blocks)\n",
    "    \n",
    "    #Discriminators\n",
    "    D_X = Discriminator(conv_dim = g_conv_dim )\n",
    "    D_Y = Discriminator(conv_dim = g_conv_dim)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        \n",
    "        #device = torch.device(\"cuda : 0\")\n",
    "        G_XtoY.cuda()\n",
    "        G_YtoX.cuda()\n",
    "        D_X.cuda()\n",
    "        D_Y.cuda()\n",
    "        \n",
    "        print(\"Models moved to GPU\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Only Cpu Available\")\n",
    "       \n",
    "    return G_XtoY , G_YtoX ,D_X , D_Y\n",
    "        \n",
    "def print_model_arch(model , model_name):\n",
    "    \n",
    "    '''This functions prints the network architecture'''\n",
    "    print(model_name)\n",
    "    print()\n",
    "    print(\"******************************************************************\")\n",
    "    print(model)\n",
    "    print()\n",
    "    print(\"******************************************************************\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aee654a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models moved to GPU\n",
      "G_XtoY\n",
      "\n",
      "******************************************************************\n",
      "Generator(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (residual_layers): Sequential(\n",
      "    (0): residual_blocks(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): residual_blocks(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): residual_blocks(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): residual_blocks(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): residual_blocks(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): residual_blocks(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (deconv1): Sequential(\n",
      "    (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (deconv2): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (deconv3): Sequential(\n",
      "    (0): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "\n",
      "******************************************************************\n",
      "\n",
      "G_YtoX\n",
      "\n",
      "******************************************************************\n",
      "Generator(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (residual_layers): Sequential(\n",
      "    (0): residual_blocks(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): residual_blocks(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): residual_blocks(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): residual_blocks(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): residual_blocks(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): residual_blocks(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (deconv1): Sequential(\n",
      "    (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (deconv2): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (deconv3): Sequential(\n",
      "    (0): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "\n",
      "******************************************************************\n",
      "\n",
      "D_X\n",
      "\n",
      "******************************************************************\n",
      "Discriminator(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(0, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(11, 11), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "\n",
      "******************************************************************\n",
      "\n",
      "D_Y\n",
      "\n",
      "******************************************************************\n",
      "Discriminator(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(0, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(11, 11), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "\n",
      "******************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating models and prinitng them\n",
    "G_XtoY , G_YtoX , D_X , D_Y = create_models()\n",
    "model_list = [G_XtoY , G_YtoX , D_X , D_Y]\n",
    "model_name_list = [ 'G_XtoY' , 'G_YtoX' , 'D_X' , 'D_Y']\n",
    "\n",
    "#Printing the archs\n",
    "for model , name in zip(model_list , model_name_list):\n",
    "    print_model_arch(model , name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c407610",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to save the models at checkpoints\n",
    "\n",
    "def save_at_checkpoints(G_XtoY , G_YtoX , D_X , D_Y , save_dir = 'model_save'):\n",
    "    \n",
    "    ''' Saves the parameters of both generators and discriminators'''\n",
    "    G_XtoY_path = os.path.join(save_dir , 'G_XtoY.pkl')\n",
    "    G_YtoX_path = os.path.join(save_dir , 'G_YtoX.pkl')\n",
    "    D_X_path = os.path.join(save_dir , 'D_X.pkl')\n",
    "    D_Y_path = os.path.join(save_dir , 'D_Y.pkl')\n",
    "    \n",
    "    torch.save(G_XtoY.state_dict() , G_XtoY_path)\n",
    "    torch.save(G_YtoX.state_dict() , G_YtoX_path)\n",
    "    torch.save(D_X.state_dict() , D_X_path)\n",
    "    torch.save(D_Y.state_dict() , D_Y_path)\n",
    "    \n",
    "def load_parameters(G_XtoY , G_YtoX , D_X , D_Y , save_dir = 'model_save'):\n",
    "    G_XtoY_path = os.path.join(save_dir , 'G_XtoY.pkl')\n",
    "    G_YtoX_path = os.path.join(save_dir , 'G_YtoX.pkl')\n",
    "    D_X_path = os.path.join(save_dir , 'D_X.pkl')\n",
    "    D_Y_path = os.path.join(save_dir , 'D_Y.pkl')\n",
    "    \n",
    "    G_XtoY.load_state_dict(torch.load(G_XtoY_path))\n",
    "    G_YtoX.load_state_dict(torch.load(G_YtoX_path))\n",
    "    D_X.load_state_dict(torch.load(D_X_path))\n",
    "    D_Y.load_state_dict(torch.load(D_Y_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bc30598",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_parameters(G_XtoY , G_YtoX , D_X , D_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc0ca1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the losses\n",
    "\n",
    "def real_mse_loss(D_out):\n",
    "    \n",
    "    #How close is the produced output from being real\n",
    "    return torch.mean((D_out - 1)**2)\n",
    "\n",
    "def fake_mse_loss(D_out):\n",
    "    \n",
    "    #How close is the produced output from being fake\n",
    "    return torch.mean((D_out - 0)**2)\n",
    "\n",
    "def cycle_cons_loss(real_im , recons_im , lambda_wt):\n",
    "    \n",
    "    return lambda_wt * (torch.mean(torch.abs(real_im - recons_im)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adbac593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_images(sources , targets , batch_size= 16):\n",
    "    \n",
    "    ''' This function creates a grid consisting of columns  , first column contains source images and second column contain the generated images'''\n",
    "   \n",
    "    _, _, h, w = sources.shape\n",
    "    row = int(np.sqrt(batch_size))\n",
    "    merged = np.zeros([3, row*h, row*w*2])\n",
    "    for idx, (s, t) in enumerate(zip(sources, targets)):\n",
    "        i = idx // row\n",
    "        j = idx % row\n",
    "        merged[:, i*h:(i+1)*h, (j*2)*h:(j*2+1)*h] = s\n",
    "        merged[:, i*h:(i+1)*h, (j*2+1)*h:(j*2+2)*h] = t\n",
    "    merged = merged.transpose(1, 2, 0)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "096c217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the optimizers\n",
    "\n",
    "lr = 0.0008\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "n_epochs = 20\n",
    "last_epoch = 350\n",
    "gen_params = list(G_XtoY.parameters()) + list(G_YtoX.parameters())\n",
    "\n",
    "g_optimizer = optim.Adam(gen_params , lr , betas = (beta1 , beta2))\n",
    "d_x_optimizer = optim.Adam(D_X.parameters() , lr , betas = (beta1 , beta2))\n",
    "d_y_optimizer = optim.Adam(D_Y.parameters() , lr , betas = (beta1 , beta2))\n",
    "losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f6ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_XtoY.train()\n",
    "G_YtoX.train()\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # Reset iterators for each epoch\n",
    "\n",
    "\n",
    "    # ============================================\n",
    "    #            TRAIN THE DISCRIMINATORS\n",
    "    # ============================================\n",
    "    for images_X, images_Y in train_loader:\n",
    "        ##   First: D_X, real and fake loss components   ##\n",
    "        images_X, images_Y = images_X.to(device), images_Y.to(device)\n",
    "        # Train with real images\n",
    "        d_x_optimizer.zero_grad()\n",
    "\n",
    "        # 1. Compute the discriminator losses on real images\n",
    "        out_x = D_X(images_X)\n",
    "        D_X_real_loss = real_mse_loss(out_x)\n",
    "\n",
    "        # Train with fake images\n",
    "\n",
    "        # 2. Generate fake images that look like domain X based on real images in domain Y\n",
    "        fake_X = G_YtoX(images_Y)\n",
    "\n",
    "        # 3. Compute the fake loss for D_X\n",
    "        out_x = D_X(fake_X)\n",
    "        D_X_fake_loss = fake_mse_loss(out_x)\n",
    "\n",
    "\n",
    "        # 4. Compute the total loss and perform backprop\n",
    "        d_x_loss = D_X_real_loss + D_X_fake_loss\n",
    "        d_x_loss.backward()\n",
    "        d_x_optimizer.step()\n",
    "\n",
    "\n",
    "        ##   Second: D_Y, real and fake loss components   ##\n",
    "\n",
    "        # Train with real images\n",
    "        d_y_optimizer.zero_grad()\n",
    "\n",
    "        # 1. Compute the discriminator losses on real images\n",
    "        out_y = D_Y(images_Y)\n",
    "        D_Y_real_loss = real_mse_loss(out_y)\n",
    "\n",
    "        # Train with fake images\n",
    "\n",
    "        # 2. Generate fake images that look like domain Y based on real images in domain X\n",
    "        fake_Y = G_XtoY(images_X)\n",
    "\n",
    "        # 3. Compute the fake loss for D_Y\n",
    "        out_y = D_Y(fake_Y)\n",
    "        D_Y_fake_loss = fake_mse_loss(out_y)\n",
    "\n",
    "        # 4. Compute the total loss and perform backprop\n",
    "        d_y_loss = D_Y_real_loss + D_Y_fake_loss\n",
    "        d_y_loss.backward()\n",
    "        d_y_optimizer.step()\n",
    "\n",
    "\n",
    "        # =========================================\n",
    "        #            TRAIN THE GENERATORS\n",
    "        # =========================================\n",
    "\n",
    "        ## First: generate fake X images and reconstructed Y images    ##\n",
    "        g_optimizer.zero_grad()\n",
    "\n",
    "        # 1. Generate fake images that look like domain X based on real images in domain Y\n",
    "        fake_X = G_YtoX(images_Y)\n",
    "\n",
    "        # 2. Compute the generator loss based on domain X\n",
    "        out_x = D_X(fake_X)\n",
    "        g_YtoX_loss = real_mse_loss(out_x)\n",
    "\n",
    "        # 3. Create a reconstructed y\n",
    "        # 4. Compute the cycle consistency loss (the reconstruction loss)\n",
    "        reconstructed_Y = G_XtoY(fake_X)\n",
    "        reconstructed_y_loss = cycle_cons_loss(images_Y, reconstructed_Y, lambda_wt=10)\n",
    "\n",
    "\n",
    "        ## Second: generate fake Y images and reconstructed X images    ##\n",
    "\n",
    "        # 1. Generate fake images that look like domain Y based on real images in domain X\n",
    "        fake_Y = G_XtoY(images_X)\n",
    "\n",
    "        # 2. Compute the generator loss based on domain Y\n",
    "        out_y = D_Y(fake_Y)\n",
    "        g_XtoY_loss = real_mse_loss(out_y)\n",
    "\n",
    "        # 3. Create a reconstructed x\n",
    "        # 4. Compute the cycle consistency loss (the reconstruction loss)\n",
    "        reconstructed_X = G_YtoX(fake_Y)\n",
    "        reconstructed_x_loss = cycle_cons_loss(images_X, reconstructed_X, lambda_wt=10)\n",
    "\n",
    "        # 5. Add up all generator and reconstructed losses and perform backprop\n",
    "        g_total_loss = g_YtoX_loss + g_XtoY_loss + reconstructed_y_loss + reconstructed_x_loss\n",
    "        g_total_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(\"{} epochs training completed and saved model\".format(epoch+last_epoch))\n",
    "        save_at_checkpoints(G_XtoY , G_YtoX , D_X , D_Y)\n",
    "        losses.append((d_x_loss.item(), d_y_loss.item(), g_total_loss.item()))\n",
    "        print('Epoch [{:5d}/{:5d}] | d_X_loss: {:6.4f} | d_Y_loss: {:6.4f} | g_total_loss: {:6.4f}'.format(\n",
    "                epoch, n_epochs, d_x_loss.item(), d_y_loss.item(), g_total_loss.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f694a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 160, 160])\n"
     ]
    }
   ],
   "source": [
    "G_XtoY.eval()\n",
    "test_iter = iter(test_loader)\n",
    "batch = next(test_iter)\n",
    "x, y = batch\n",
    "x = x.to(device)\n",
    "y_pred = G_XtoY(x)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06179d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.cpu()\n",
    "y_pred = y_pred.permute(0, 2, 3, 1)\n",
    "y = y.permute(0, 2, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_8_images_tensor1 = y_pred[:8].detach().numpy()\n",
    "first_8_images_tensor2 = y[:8].detach().numpy()\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "\n",
    "# Loop through and display the images from the first tensor\n",
    "for i in range(8):\n",
    "    axes[0, i].imshow(first_8_images_tensor1[i])\n",
    "    axes[0, i].axis('off')  # Turn off axis labels\n",
    "\n",
    "# Loop through and display the images from the second tensor\n",
    "for i in range(8):\n",
    "    axes[1, i].imshow(first_8_images_tensor2[i])\n",
    "    axes[1, i].axis('off')  # Turn off axis labels\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533a50a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
